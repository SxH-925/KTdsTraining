import os
import re
import json
from dotenv import load_dotenv
from openai import AzureOpenAI
import streamlit as st
from streamlit_ace import st_ace  # ì¶”ê°€

# Load environment variables
load_dotenv()

openai_endpoint = os.getenv("OPENAI_ENDPOINT")
openai_api_key = os.getenv("OPENAI_API_KEY")
chat_model = os.getenv("CHAT_MODEL")
search_endpoint = os.getenv("SEARCH_ENDPOINT")
search_api_key = os.getenv("SEARCH_API_KEY")
index_name = os.getenv("INDEX_NAME")

# Initialize Azure OpenAI client
chat_client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint=openai_endpoint,
    api_key=openai_api_key
)

st.set_page_config(page_title="CodeInspection Assistant", layout="wide")

# --- ì‚¬ì´ë“œë°” ì¶”ê°€ ---
st.sidebar.image("data/logo.png", width=100)
if st.sidebar.button("ğŸ§° MVP ê³¼ì œ", use_container_width=True):
    st.session_state.menu = "mvp"

# --- ë©”ì¸ í™”ë©´ í—¤ë” ---
st.markdown("""
<div style='padding: 1.5rem 1rem; background: linear-gradient(90deg, #EEAECA 0%, #94BBE9 100%); border-radius: 0.75rem;'>
  <h1 style='color: white; font-size: 2.2rem; margin-bottom: 0.5rem;'>âŒ¨ï¸ CodeEyes Assistant</h1>
  <p style='color: #f0f0f0; font-size: 1.1rem;'>ğŸ’¡ SonarQube ë£° ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ë° ìˆ˜ì • ì½”ë“œ ì œì•ˆì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.</p>
</div>
""", unsafe_allow_html=True)

st.divider()

# --- Load system prompt from file ---
def load_system_prompt():
    with open("prompt/system_prompt.md", "r", encoding="utf-8") as f:
        return f.read()

# --- ì´ˆê¸° System Prompt ì„¤ì • ---
if "messages" not in st.session_state:
    st.session_state.followup_response = ""
    st.session_state.messages = [
        {
            "role": "system",
            "content": load_system_prompt()
        }
    ]

# --- LLM ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ ---
def get_openai_response(messages=None, use_rag=True, search_endpoint=None, search_api_key=None, index_name=None):
    rag_params = {
        "data_sources": [
            {
                "type": "azure_search",
                "parameters": {
                    "endpoint": search_endpoint,
                    "index_name": index_name,
                    "authentication": {
                        "type": "api_key",
                        "key": search_api_key,
                    }
                }
            }
        ]
    } if use_rag and search_endpoint and search_api_key and index_name else {}

    if messages is None:
        messages = st.session_state.messages  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¸ì…˜ì˜ ë©”ì‹œì§€ ì‚¬ìš©

    response = chat_client.chat.completions.create(
        model=chat_model,
        messages=messages,
        extra_body=rag_params
    )
    return response.choices[0].message.content


# --- Markdown íŒŒì‹± í•¨ìˆ˜ ---
def normalize_verdict(text):
    if not text:
        return None
    lowered = text.lower()
    if "ì •íƒ" in lowered:
        return "ì •íƒ"
    elif "ì˜¤íƒ" in lowered:
        return "ì˜¤íƒ"
    return None

def parse_markdown_response(markdown_text):
    parsed = {}

    parsed['rule'] = re.search(r"##+\s*(?:[\W_]*\s*)?Rule[:ï¼š]?\s*(.+)", markdown_text)
    parsed['severity'] = re.search(r"\*\*ë“±ê¸‰\*\*: *(.+)", markdown_text)
    parsed['category'] = re.search(r"\*\*ë²”ì£¼\*\*: *(.+)", markdown_text)
    parsed['description'] = re.search(r"\*\*ì„¤ëª…\*\*: *\n?(.+?)(?=\n\*\*ì˜¤íƒ/ì •íƒ ì—¬ë¶€\*\*:)", markdown_text, re.DOTALL)
    parsed['verdict'] = re.search(r"\*\*ì˜¤íƒ/ì •íƒ ì—¬ë¶€\*\*: *`?([^\n*`]+)`?", markdown_text)
    parsed['difficulty'] = re.search(r"\*\*ìˆ˜ì • ë‚œì´ë„\*\*: *`?([^\n*`]+)`?", markdown_text)
    parsed['fix_code'] = re.search(r"```(?:[a-zA-Z]+)?\n(.+?)\n```", markdown_text, re.DOTALL)
    parsed['relevance'] = re.search(r"\*\*ê´€ë ¨ì„±\*\*: *`?([^\n*`]+)`?", markdown_text)

    result = {
        "rule": parsed['rule'].group(1).strip() if parsed['rule'] else None,
        "severity": parsed['severity'].group(1).strip() if parsed['severity'] else None,
        "category": parsed['category'].group(1).strip() if parsed['category'] else None,
        "description": parsed['description'].group(1).strip() if parsed['description'] else None,
        "verdict": normalize_verdict(parsed['verdict'].group(1).strip()) if parsed['verdict'] else None,
        "difficulty": parsed['difficulty'].group(1).strip() if parsed['difficulty'] else None,
        "fix_code": parsed['fix_code'].group(1).strip() if parsed['fix_code'] else None,
        "relevance": parsed['relevance'].group(1).strip() if parsed['relevance'] else "ì—†ìŒ"
    }

    if result["verdict"] == "ì •íƒ" and not result["fix_code"]:
        result["parse_error"] = "ì •íƒì¸ë° ìˆ˜ì • ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
    elif result["verdict"] == "ì˜¤íƒ" and not result["difficulty"]:
        result["parse_error"] = "ì˜¤íƒì¸ë° ë‚œì´ë„ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤"
    elif not result["verdict"]:
        result["parse_error"] = "ì •íƒ/ì˜¤íƒ ì—¬ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

    return result

# --- ìˆ˜ì • ì½”ë“œë§Œ ì¬ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ---
def regenerate_fix_code():
    # ê¸°ì¡´ ë©”ì‹œì§€ë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš© (ì›ë³¸ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    temp_messages = st.session_state.messages.copy()

    # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ ì œê±°í•˜ê³  ìƒˆë¡œ êµ¬ì„±
    if temp_messages[-1]["role"] == "user" and "ìˆ˜ì • ì½”ë“œë§Œ ë‹¤ì‹œ ìƒì„±í•´ì¤˜" in temp_messages[-1]["content"]:
        temp_messages.pop()

    temp_messages.append({
        "role": "user",
        "content": f"ìœ„ ì½”ë“œì— ëŒ€í•´ ìˆ˜ì • ì½”ë“œë§Œ ë‹¤ì‹œ ìƒì„±í•´ì¤˜. ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ ì½”ë“œ ë¸”ë¡ë§Œ ì¶œë ¥í•´ì¤˜."
    })

    rag_params = {}  # regenerateëŠ” RAG ë¹„í™œì„±í™”ë¡œ ì§„í–‰
    response = chat_client.chat.completions.create(
        model=chat_model,
        messages=temp_messages,
        extra_body=rag_params
    )
    return response.choices[0].message.content


# --- Input UI + Result ---
with st.expander("ğŸ›  ë¶„ì„ ì •ë³´ ì…ë ¥", expanded=True):
    col_lang, col_rule = st.columns([1, 3])
    with col_lang:
        language = st.selectbox("ì–¸ì–´", ["Python", "Java", "JavaScript"], index=0)

    with col_rule:
        with open("data/rules_list.json", "r", encoding="utf-8") as f:
            rule_db = json.load(f)
        rule_options = rule_db.get(language, [])
        rule_titles = [f"{r['title']}" for r in rule_options]
        selected_rule = st.selectbox("ë£° ì„ íƒ (ì…ë ¥ ì‹œ ìë™ ê²€ìƒ‰)", options=rule_titles)

    rulename = selected_rule.split(" - ")[0] if selected_rule else ""

    st.markdown("**ğŸ”¤ ë¶„ì„í•  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:**")
    code = st_ace(language=language.lower(), theme="monokai", height=300, key="ace_input", auto_update=True)

    analyze_button = st.button("ğŸš€ Analyze", use_container_width=True, disabled=not (rulename.strip() and code and code.strip()))

    if analyze_button:
        st.session_state.followup_response = ""
        with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.messages.append({
                "role": "user",
                "content": f"language: {language}\nrulename: {rulename}\ncode:\n{code}"
            })
            result_markdown = get_openai_response()
            parsed_result = parse_markdown_response(result_markdown)

            if parsed_result.get("parse_error"):
                st.markdown("#### [ë””ë²„ê·¸] ì‘ë‹µ ì›ë¬¸")
                st.code(result_markdown)
                st.error(f"âŒ ë¶„ì„ ê²°ê³¼ë¥¼ ì •ìƒì ìœ¼ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ì¸: {parsed_result['parse_error']}")
                st.stop()

            st.session_state.analysis_result = parsed_result

# --- ë¶„ì„ ê²°ê³¼ í‘œì‹œ ---
if "analysis_result" in st.session_state:
    st.markdown("---")
    st.markdown("#### ğŸ“Š ë¶„ì„ ê²°ê³¼")

    result = st.session_state.analysis_result
    st.subheader(f"ğŸ§¾ ë£°ëª…: {result['rule']}")
    st.markdown(f"**ë“±ê¸‰**: {result['severity']}  ")
    st.markdown(f"**ë²”ì£¼**: {result['category']}")
    st.markdown(f"**ì„¤ëª…**: {result['description'] if result['description'] else 'N/A'}")

    relevance = result.get("relevance", "").strip()
    if relevance not in ["ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ", "ì—†ìŒ"]:
        st.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ê´€ë ¨ì„± ê°’: `{relevance}` (GPT ì‘ë‹µ ì´ìƒ ê°€ëŠ¥ì„±)")
    elif relevance in ["ì—†ìŒ", "ë‚®ìŒ"]:
        st.warning("âš ï¸ ì„ íƒí•œ ë£°ê³¼ ì…ë ¥í•œ ì½”ë“œ ì‚¬ì´ì˜ ê´€ë ¨ì„±ì´ ë‚®ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤. GPTì˜ ì‘ë‹µì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if result['verdict']:
        if result['verdict'] == "ì •íƒ":
            st.markdown("**ğŸ§  ì •íƒ/ì˜¤íƒ ì—¬ë¶€**: :green[`ì •íƒ`]")
            if result.get("difficulty"):
                st.markdown(f"**ğŸ› ï¸ ìˆ˜ì • ë‚œì´ë„**: `{result['difficulty']}`")
                st.info("âš ï¸ ìƒì„±ëœ ì½”ë“œëŠ” AIê°€ ì œì•ˆí•œ ì˜ˆì‹œì´ë©°, ê°œë°œìì˜ ê²€í†  í›„ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        elif result['verdict'] == "ì˜¤íƒ":
            st.markdown("**ğŸ§  ì •íƒ/ì˜¤íƒ ì—¬ë¶€**: :orange[`ì˜¤íƒ`]")
        else:
            st.markdown("**ğŸ§  ì •íƒ/ì˜¤íƒ ì—¬ë¶€**: :red[`ì•Œ ìˆ˜ ì—†ìŒ`]")
    else:
        st.markdown("**ğŸ§  ì •íƒ/ì˜¤íƒ ì—¬ë¶€**: :red[`ë¶„ì„ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸í™•ì¸`]")

    # ìˆ˜ì • ì½”ë“œ ì œì•ˆ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if result['verdict'] == "ì •íƒ":
        if result['fix_code']:
            st.markdown("### âœ… ìˆ˜ì • ì½”ë“œ ì œì•ˆ")
            st.code(result['fix_code'], language=language.lower())
        else:
            st.warning("âœ… ì •íƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆì§€ë§Œ, ìˆ˜ì • ì½”ë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ìœ¼ë¡œ ìš”ì²­í•´ ë³´ì„¸ìš”.")

        # ë²„íŠ¼ ë‘ ê°œë¥¼ ê°™ì€ í–‰ì— ê°€ë¡œ 50%ì”© ë°°ì¹˜
        btn_dl, btn_regen = st.columns(2)
        with btn_dl:
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(result, ensure_ascii=False, indent=2),
                file_name="analysis_result.json",
                mime="application/json",
                use_container_width=True
            )
        with btn_regen:
            if st.button("ğŸ”„ ìˆ˜ì • ì½”ë“œ ë‹¤ì‹œ ë§Œë“¤ê¸°", use_container_width=True):
                with st.spinner("ìˆ˜ì • ì½”ë“œ ë‹¤ì‹œ ìƒì„± ì¤‘..."):
                    regenerated = regenerate_fix_code()
                    st.session_state.regenerated_code = regenerated  # ìƒíƒœë¡œ ì €ì¥

    # ìƒˆë¡œ ìƒì„±ëœ ì½”ë“œ ì¶œë ¥ (í•­ìƒ ì „ì²´ ë„ˆë¹„)
    if "regenerated_code" in st.session_state:
        st.markdown("### ğŸ”„ ìƒˆë¡œ ìƒì„±ëœ ìˆ˜ì • ì½”ë“œ")
        st.code(st.session_state.regenerated_code, language=language.lower())


    st.markdown("---")
    followup = st.text_area("ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="followup_input")

    if followup:
        st.markdown("---")
        st.markdown("#### ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ AIì˜ ë‹µë³€")
        st.session_state.messages.append({"role": "user", "content": followup})
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            followup_response = get_openai_response(use_rag=True)
        st.session_state.messages.append({"role": "assistant", "content": followup_response})
        st.session_state.followup_response = followup_response

    if "followup_response" in st.session_state:
        answer = st.session_state.followup_response
        if "The requested information is not found" in answer:
            answer = "**ì£„ì†¡í•©ë‹ˆë‹¤. ì´ AIëŠ” SonarQube ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ ì ê²€ê³¼ ë£° ì„¤ëª…ì—ë§Œ ì‘ë‹µí•©ë‹ˆë‹¤.**"
        st.markdown("**AI ë‹µë³€:**")
        st.markdown(answer)
