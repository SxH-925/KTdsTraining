import os
import re
import json
import streamlit as st
from streamlit_ace import st_ace
from config import load_system_prompt, load_rule_list, search_endpoint, search_api_key, index_name
from parser import parse_markdown_response
from llm import get_openai_response, regenerate_fix_code
from config import load_system_prompt

system_prompt = load_system_prompt()

st.set_page_config(page_title="CodeEyes Assistant", layout="wide")

# --- ì‚¬ì´ë“œë°” ---
st.sidebar.image("data/logo.png", width=100)
if st.sidebar.button("ğŸ§° MVP ê³¼ì œ", use_container_width=True):
    st.session_state.menu = "mvp"

# --- í—¤ë” ---
st.markdown("""
<style>
@keyframes wave {
  0% { background-position: 0% 50%; }
  50% { background-position: 100% 50%; }
  100% { background-position: 0% 50%; }
}

.wave-header {
  animation: wave 8s ease-in-out infinite;
  background: linear-gradient(270deg, #EEAECA, #94BBE9);
  background-size: 400% 400%;
  padding: 1.5rem 1rem;
  border-radius: 0.75rem;
}
.wave-header h1 {
  color: white;
  font-size: 2.2rem;
  margin-bottom: 0.5rem;
}
.wave-header p {
  color: #f0f0f0;
  font-size: 1.1rem;
}
</style>

<div class='wave-header'>
  <h1>âŒ¨ï¸ CodeEyes Assistant</h1>
  <p>ğŸ’¡ SonarQube ë£° ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ ë¶„ì„ ë° ìˆ˜ì • ì½”ë“œ ì œì•ˆì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤.</p>
</div>
""", unsafe_allow_html=True)


st.divider()


# --- ì„¸ì…˜ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.followup_response = ""
    st.session_state.messages = [{"role": "system", "content": load_system_prompt()}]

# --- ì…ë ¥ UI ---
with st.expander("ğŸ›  ë¶„ì„ ì •ë³´ ì…ë ¥", expanded=True):
    col_lang, col_rule = st.columns([1, 3])
    with col_lang:
        language = st.selectbox("ì–¸ì–´", ["Python", "Java", "JavaScript"], index=0)
        language = language.lower()  # RAG ì²˜ë¦¬ ë° ë£° í•„í„°ë§ ì¼ê´€ì„± í™•ë³´

    with col_rule:
        rule_list = load_rule_list(language)
        rule_titles = [f"{r['title']}" for r in rule_list]
        selected_rule = st.selectbox("ë£° ì„ íƒ (ì…ë ¥ ì‹œ ìë™ ê²€ìƒ‰)", options=rule_titles)

    rulename = selected_rule.split(" - ")[0] if selected_rule else ""

    st.markdown("**ğŸ”¤ ë¶„ì„í•  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:**") 
    dark_mode = st.toggle("ğŸŒ™ ì—ë””í„° ë‹¤í¬ ëª¨ë“œ", value=True)
    theme = "dracula" if dark_mode else "github"
    code = st_ace(language=language.lower(), theme=theme, height=300, key="ace_input", auto_update=True)

    analyze_button = st.button("ğŸš€ Analyze", use_container_width=True, disabled=not (rulename.strip() and code and code.strip()))

    if analyze_button:
        st.session_state.followup_response = ""
        with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.messages.append({
                "role": "user",
                "content": f"language: {language}\nrulename: {rulename}\ncode:\n{code}"
            })
            result_markdown = get_openai_response(
                messages=st.session_state.messages,
                use_rag=True,
                search_endpoint=search_endpoint,
                search_api_key=search_api_key,
                index_name=index_name
            )
            parsed_result = parse_markdown_response(result_markdown)

            if parsed_result.get("parse_error"):
                st.markdown("#### [ë””ë²„ê·¸] ì‘ë‹µ ì›ë¬¸")
                st.code(result_markdown)
                st.error(f"âŒ ë¶„ì„ ê²°ê³¼ë¥¼ ì •ìƒì ìœ¼ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ì¸: {parsed_result['parse_error']}")
                st.stop()

            st.session_state.analysis_result = parsed_result

# --- ë¶„ì„ ê²°ê³¼ ---
if "analysis_result" in st.session_state:
    # st.write("ğŸ’¬ ìš”ì²­ ë©”ì‹œì§€:", st.session_state.messages)
    st.markdown("---")
    st.markdown("#### ğŸ“Š ë¶„ì„ ê²°ê³¼")

    result = st.session_state.analysis_result
    st.subheader(f"ğŸ§¾ ë£°ëª…: {result['rule']}")
    st.markdown(f"**ë“±ê¸‰**: {result['severity']}")
    st.markdown(f"**ë²”ì£¼**: {result['category']}")
    st.markdown(f"**ì„¤ëª…**: {result['description'] if result['description'] else 'N/A'}")

    relevance = result.get("relevance", "").strip()
    if relevance not in ["ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ", "ì—†ìŒ"]:
        st.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ê´€ë ¨ì„± ê°’: `{relevance}` (GPT ì‘ë‹µ ì´ìƒ ê°€ëŠ¥ì„±)")
    elif relevance in ["ì—†ìŒ", "ë‚®ìŒ"]:
        st.warning("âš ï¸ ì„ íƒí•œ ë£°ê³¼ ì…ë ¥í•œ ì½”ë“œ ì‚¬ì´ì˜ ê´€ë ¨ì„±ì´ ë‚®ê±°ë‚˜ ì—†ìŠµë‹ˆë‹¤. GPTì˜ ì‘ë‹µì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if result['verdict']:
        st.markdown(f"**ğŸ§  ì •íƒ/ì˜¤íƒ ì—¬ë¶€**: :{'green' if result['verdict']=='ì •íƒ' else 'orange'}[`{result['verdict']}`]")
        if result['verdict'] == "ì •íƒ" and result.get("difficulty"):
            st.markdown(f"**ğŸ› ï¸ ìˆ˜ì • ë‚œì´ë„**: `{result['difficulty']}`")
            st.info("âš ï¸ ìƒì„±ëœ ì½”ë“œëŠ” AIê°€ ì œì•ˆí•œ ì˜ˆì‹œì´ë©°, ê°œë°œìì˜ ê²€í†  í›„ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    # ìˆ˜ì • ì½”ë“œ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if result['verdict'] == "ì •íƒ":
        if result['fix_code']:
            st.markdown("### âœ… ìˆ˜ì • ì½”ë“œ ì œì•ˆ")
            st.code(result['fix_code'], language=language.lower())
        else:
            st.warning("âœ… ì •íƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆì§€ë§Œ, ìˆ˜ì • ì½”ë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ìœ¼ë¡œ ìš”ì²­í•´ ë³´ì„¸ìš”.")

        btn_dl, btn_regen = st.columns(2)
        with btn_dl:
            st.download_button("ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", json.dumps(result, ensure_ascii=False, indent=2), file_name="analysis_result.json", mime="application/json", use_container_width=True)
        with btn_regen:
            if st.button("ğŸ”„ ìˆ˜ì • ì½”ë“œ ë‹¤ì‹œ ë§Œë“¤ê¸°", use_container_width=True):
                with st.spinner("ìˆ˜ì • ì½”ë“œ ë‹¤ì‹œ ìƒì„± ì¤‘..."):
                    regenerated = regenerate_fix_code(st.session_state.messages)
                    st.session_state.regenerated_code = regenerated

    if "regenerated_code" in st.session_state:
        st.markdown("### ğŸ”„ ìƒˆë¡œ ìƒì„±ëœ ìˆ˜ì • ì½”ë“œ")
        st.code(st.session_state.regenerated_code, language=language.lower())

    st.markdown("---")
    followup = st.text_area("ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="followup_input")

    if followup:
        st.markdown("---")
        st.markdown("#### ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ AIì˜ ë‹µë³€")

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ì‹œ í¬í•¨í•œ ë©”ì‹œì§€ ì¬êµ¬ì„±
        followup_messages = [
            {"role": "system", "content": system_prompt},  # ë‹¤ì‹œ ì£¼ì…
        ] + st.session_state.messages[1:]  # ê¸°ì¡´ user-assistant ê¸°ë¡ ìœ ì§€

        followup_messages.append({"role": "user", "content": followup + "\n\nì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ë§Œ í•´ì£¼ê³ , ë‹¤ë¥¸ ë¶„ì„ ê²°ê³¼ í•­ëª©ì€ ë°˜ë³µí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤."})

        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            followup_response = get_openai_response(followup_messages, use_rag=True)

        st.session_state.messages.append({"role": "assistant", "content": followup_response})
        st.session_state.followup_response = followup_response

    if "followup_response" in st.session_state:
        answer = st.session_state.followup_response
        if "The requested information is not found" in answer:
            answer = "**ì£„ì†¡í•©ë‹ˆë‹¤. ì´ AIëŠ” SonarQube ê¸°ë°˜ ì½”ë“œ í’ˆì§ˆ ì ê²€ê³¼ ë£° ì„¤ëª…ì—ë§Œ ì‘ë‹µí•©ë‹ˆë‹¤.**"
        st.markdown("**AI ë‹µë³€:**")
        st.markdown(answer)
